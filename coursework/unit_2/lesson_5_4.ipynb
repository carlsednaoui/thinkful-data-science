{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients from sklearn: \n",
      " [[ 1.99859925]]\n",
      "\n",
      "Intercept from sklearn: \n",
      " [ 0.53292363]\n",
      "******\n",
      "We needed 218 itterations\n",
      "******\n",
      "\n",
      "Coefficients from gradient descent algorithm: \n",
      " 1.78606879169\n",
      "\n",
      "Intercept from gradient descent algorithm: \n",
      " 0.51847419199\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUBMEPgDUBIEPADVB4ANATfw/9MQnwnK21k8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d9b9f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STOP_THRESHOLD = 0.001\n",
    "ITER_COUNT = 0\n",
    "\n",
    "## Cost function for the linear regression that we will try to optimize.\n",
    "def LR_cost_function (alpha, beta, x, y):\n",
    "    '''Return the cost for a given line and data.\n",
    "    \n",
    "    Alpha and beta are the coeficients that describe the fit line line, while\n",
    "    x and y are lists or arrays with the x and y value of each data point.\n",
    "    '''\n",
    "    error = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        point_error = (y[i] - (alpha + beta * x[i])) ** 2\n",
    "        error += point_error\n",
    "    return error / n\n",
    "\n",
    "\n",
    "# Function we'll call each iteration (or step) of the gradient algorithm.\n",
    "def step (alpha_cur, beta_cur, learning_rate, x, y):\n",
    "    '''Move downhill from a current cost function to a new, more optimal one.'''\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        # Partial derivative of the intercept.\n",
    "        point_alpha = -(2 / n) * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        alpha += point_alpha\n",
    "        \n",
    "        # Partial derivative of the slope.\n",
    "        point_beta = -(2 / n) * x[i] * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        beta += point_beta\n",
    "        \n",
    "    new_alpha = alpha_cur - learning_rate * alpha \n",
    "    new_beta = beta_cur - learning_rate * beta\n",
    "    return [new_alpha, new_beta]\n",
    "\n",
    "# These constants correspond to the decision-points described above.\n",
    "# How many steps to take.\n",
    "stop = 1000\n",
    "\n",
    "# How far to move with each step.\n",
    "learning_rate = .005\n",
    "\n",
    "# Starting values for intercept and slope \n",
    "alpha_start = 0\n",
    "beta_start = 0\n",
    "\n",
    "# Time to make some data!\n",
    "x = np.random.normal(0, 1, 100)\n",
    "y = x * 2 + np.random.sample(100)\n",
    "\n",
    "# Fit an true minimum regression using solved equations.\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "\n",
    "print('\\nCoefficients from sklearn: \\n', regr.coef_)\n",
    "print('\\nIntercept from sklearn: \\n', regr.intercept_)\n",
    "\n",
    "\n",
    "# Now fit an iteratively optimized regression using your custom gradient\n",
    "# descent algorithm.\n",
    "\n",
    "# Storing each iteration to inspect later.\n",
    "all_error=[]\n",
    "\n",
    "# Provide starting values.\n",
    "alpha = alpha_start\n",
    "beta = beta_start\n",
    "\n",
    "#Run the algorithm.\n",
    "for iter in range(stop):\n",
    "    \n",
    "    # Take a step, assigning the results of our step function to feed into\n",
    "    # the next step.\n",
    "    alpha, beta = step(alpha, beta, learning_rate, x, y)\n",
    "    ITER_COUNT += 1\n",
    "    if len(all_error) > 2:\n",
    "        if all_error[-2] - all_error[-1] < STOP_THRESHOLD:\n",
    "            print(\"******\")\n",
    "            print(\"We needed {} itterations\".format(ITER_COUNT))\n",
    "            print(\"******\")\n",
    "            break\n",
    "    \n",
    "    \n",
    "    # Calculate the error.\n",
    "    error = LR_cost_function(alpha, beta, x, y)\n",
    "    \n",
    "    # Store the error to instpect later.\n",
    "    all_error.append(error)\n",
    "\n",
    "    \n",
    "print('\\nCoefficients from gradient descent algorithm: \\n', beta)\n",
    "print('\\nIntercept from gradient descent algorithm: \\n', alpha)\n",
    "\n",
    "plt.plot(all_error, 'o', ms=.4)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error scores for each iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
