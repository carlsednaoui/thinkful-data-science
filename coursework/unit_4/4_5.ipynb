{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cart-abandon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4666, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"all_text\"] = df[\"subject\"] + \" \" + df[\"full_text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_id</th>\n",
       "      <th>add_id</th>\n",
       "      <th>email_guid</th>\n",
       "      <th>sent_at</th>\n",
       "      <th>subject</th>\n",
       "      <th>full_text</th>\n",
       "      <th>r</th>\n",
       "      <th>email_url</th>\n",
       "      <th>cart_abandon</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>f3870de1-3ab6-3fed-3fe2-778a74f3197e</td>\n",
       "      <td>1/7/16 15:07</td>\n",
       "      <td>Welcome to Sephora Beauty Insider</td>\n",
       "      <td>Lorem, you're a Beauty Insider. Web Version SE...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.mailcharts.com/emails/f3870de1-3ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to Sephora Beauty Insider Lorem, you'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70</td>\n",
       "      <td>1/8/16 17:28</td>\n",
       "      <td>New year, new rewards</td>\n",
       "      <td>Lorem, the January rewards are here.** Web Ver...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.mailcharts.com/emails/0880fd5c-fbc...</td>\n",
       "      <td>0</td>\n",
       "      <td>New year, new rewards Lorem, the January rewar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_id  add_id                            email_guid       sent_at  \\\n",
       "0    2582    3742  f3870de1-3ab6-3fed-3fe2-778a74f3197e  1/7/16 15:07   \n",
       "1    2582    3742  0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70  1/8/16 17:28   \n",
       "\n",
       "                             subject  \\\n",
       "0  Welcome to Sephora Beauty Insider   \n",
       "1              New year, new rewards   \n",
       "\n",
       "                                           full_text  r  \\\n",
       "0  Lorem, you're a Beauty Insider. Web Version SE...  1   \n",
       "1  Lorem, the January rewards are here.** Web Ver...  2   \n",
       "\n",
       "                                           email_url cart_abandon  \\\n",
       "0  https://www.mailcharts.com/emails/f3870de1-3ab...            0   \n",
       "1  https://www.mailcharts.com/emails/0880fd5c-fbc...            0   \n",
       "\n",
       "                                            all_text  \n",
       "0  Welcome to Sephora Beauty Insider Lorem, you'r...  \n",
       "1  New year, new rewards Lorem, the January rewar...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "import string\n",
    "\n",
    "\n",
    "# Steps: Clean up text, stemming, remove stop words and weird chars, tokenizer words\n",
    "\n",
    "# punctuation = list(set(string.punctuation))\n",
    "re_punctuation = \"\\#|\\.|\\>|\\/|\\)|\\\"|\\(|\\}|\\'|\\_|\\-|\\$|\\:|\\[|\\^|\\+|\\?|\\`|\\~|\\!|\\<|\\@|\\;|\\=|\\*|\\\\\\|\\{|\\&|\\]|\\||\\,|\\|\"\n",
    "stopwords_set = list(set(stopwords.words('english')))\n",
    "\n",
    "def get_unigram_sentence(sentence):\n",
    "    sentence_no_punc = re.sub(re_punctuation, \" \", sentence)\n",
    "    unigram = [word for word in word_tokenize(sentence_no_punc.lower()) if word not in stopwords_set]\n",
    "    return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"tokenized_text\"] = df.all_text.apply(lambda x: get_unigram_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_id</th>\n",
       "      <th>add_id</th>\n",
       "      <th>email_guid</th>\n",
       "      <th>sent_at</th>\n",
       "      <th>subject</th>\n",
       "      <th>full_text</th>\n",
       "      <th>r</th>\n",
       "      <th>email_url</th>\n",
       "      <th>cart_abandon</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>f3870de1-3ab6-3fed-3fe2-778a74f3197e</td>\n",
       "      <td>1/7/16 15:07</td>\n",
       "      <td>Welcome to Sephora Beauty Insider</td>\n",
       "      <td>Lorem, you're a Beauty Insider. Web Version SE...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.mailcharts.com/emails/f3870de1-3ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to Sephora Beauty Insider Lorem, you'r...</td>\n",
       "      <td>[welcome, sephora, beauty, insider, lorem, bea...</td>\n",
       "      <td>[welcom, sephora, beauti, insid, lorem, 're, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70</td>\n",
       "      <td>1/8/16 17:28</td>\n",
       "      <td>New year, new rewards</td>\n",
       "      <td>Lorem, the January rewards are here.** Web Ver...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.mailcharts.com/emails/0880fd5c-fbc...</td>\n",
       "      <td>0</td>\n",
       "      <td>New year, new rewards Lorem, the January rewar...</td>\n",
       "      <td>[new, year, new, rewards, lorem, january, rewa...</td>\n",
       "      <td>[new, year, new, reward, lorem, januari, rewar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_id  add_id                            email_guid       sent_at  \\\n",
       "0    2582    3742  f3870de1-3ab6-3fed-3fe2-778a74f3197e  1/7/16 15:07   \n",
       "1    2582    3742  0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70  1/8/16 17:28   \n",
       "\n",
       "                             subject  \\\n",
       "0  Welcome to Sephora Beauty Insider   \n",
       "1              New year, new rewards   \n",
       "\n",
       "                                           full_text  r  \\\n",
       "0  Lorem, you're a Beauty Insider. Web Version SE...  1   \n",
       "1  Lorem, the January rewards are here.** Web Ver...  2   \n",
       "\n",
       "                                           email_url cart_abandon  \\\n",
       "0  https://www.mailcharts.com/emails/f3870de1-3ab...            0   \n",
       "1  https://www.mailcharts.com/emails/0880fd5c-fbc...            0   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  Welcome to Sephora Beauty Insider Lorem, you'r...   \n",
       "1  New year, new rewards Lorem, the January rewar...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [welcome, sephora, beauty, insider, lorem, bea...   \n",
       "1  [new, year, new, rewards, lorem, january, rewa...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  [welcom, sephora, beauti, insid, lorem, 're, b...  \n",
       "1  [new, year, new, reward, lorem, januari, rewar...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_stems(words):\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"stemmed_tokens\"] = df.tokenized_text.apply(lambda x: get_stems(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"stemmed_text\"] = df[\"stemmed_tokens\"].apply(lambda x: \" \".join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df[\"stemmed_text\"])\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carl/anaconda/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_jobs=1, n_topics=10, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "    for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('shopbop', 2.75898794576303), ('lola', 1.7909009684246469), ('wigwam', 0.85717691783088545), ('¹ã', 0.73548630582397523), ('âºã', 0.7354842593903117), ('shopnicekick', 0.69220575079958191), ('5yp', 0.63933284654281608), ('s9j', 0.63933282964942451), ('l6v', 0.63933243342710921), ('yv1', 0.6393323065449773)]\n",
      "====================================================================================================\n",
      "Topic 1:\n",
      "[('html', 27.820518055734379), ('version', 17.494157535777209), ('hammach', 4.7603372594176268), ('schlemmer', 2.7903521663425614), ('maxdeliveri', 2.1735532740091439), ('œnâ', 2.1432913414764045), ('thorlo', 2.0194295493759973), ('chesapeak', 2.0130716201603938), ('œaâ', 1.8513819881259777), ('wigwam', 1.4765636063212964)]\n",
      "====================================================================================================\n",
      "Topic 2:\n",
      "[('rawl', 3.2670056900662301), ('bbcor', 1.1572385220075427), ('her', 0.98404196490944051), ('508', 0.84883538636880773), ('knockaroundâ', 0.75979221117168105), ('4327', 0.59505025986379745), ('demarini', 0.44822250693559917), ('510', 0.43711174358781052), ('63141', 0.4371100169886673), ('maryvil', 0.43710974039869888)]\n",
      "====================================================================================================\n",
      "Topic 3:\n",
      "[('ashley', 3.1671193011975554), ('homestor', 2.4483914531008404), ('baldridg', 0.93379815160407742), ('luxi', 0.85366551570082705), ('54612', 0.80859970487096688), ('herschel', 0.65339663516688373), ('laf', 0.57390257192791083), ('chais', 0.52197077552600013), ('plndr', 0.49551733029243028), ('kazbah', 0.47400536229388518)]\n",
      "====================================================================================================\n",
      "Topic 4:\n",
      "[('de', 9.5385684979544649), ('para', 3.1446046900925211), ('keen', 2.3286684563933302), ('tu', 2.2278340307156497), ('dafiti', 2.2134892487005629), ('oliv', 2.1991261095550247), ('en', 2.1906738821952314), ('vou', 2.1422816595235261), ('que', 1.9976006256071845), ('gaudena', 1.9791932580214477)]\n",
      "====================================================================================================\n",
      "Topic 5:\n",
      "[('email', 165.69192105703334), ('shop', 142.86253616378232), ('xxx', 138.57019535015291), ('com', 119.91529915292475), ('us', 117.24734799843988), ('order', 116.50475319283042), ('ship', 111.50565913137088), ('offer', 108.48133680503837), ('free', 105.01634788463612), ('account', 95.060709121414007)]\n",
      "====================================================================================================\n",
      "Topic 6:\n",
      "[('confirm', 35.417746425898194), ('subscrib', 22.080703790627897), ('subscript', 22.047635471172082), ('delet', 15.141780226666151), ('ye', 14.451070035881672), ('mistak', 14.191750464093209), ('list', 13.92915893219287), ('newslett', 13.268052169821805), ('pleas', 10.762492536629908), ('link', 9.4775440432457252)]\n",
      "====================================================================================================\n",
      "Topic 7:\n",
      "[('furla', 3.0652047976079895), ('comprivaci', 0.89041211744757576), ('sixth', 0.84082862867036934), ('metropoli', 0.68940197482472076), ('tna', 0.60483357018465844), ('lazzaro', 0.58062185982615078), ('savena', 0.58061314391695873), ('40068', 0.58059592554961281), ('it00610091209', 0.58055517920424293), ('bellaria', 0.58038497124229427)]\n",
      "====================================================================================================\n",
      "Topic 8:\n",
      "[('nordstrom', 4.8461730623834756), ('harvard', 2.1854448663690373), ('koyal', 1.8110627600899458), ('golfz', 1.0896185646669161), ('hautelook', 0.8138834948668503), ('m5t', 0.78774144293706172), ('174', 0.63532585703936195), ('spadina', 0.63531612741701204), ('2c2', 0.6353085445067983), ('fã', 0.60024227602338098)]\n",
      "====================================================================================================\n",
      "Topic 9:\n",
      "[('harrod', 1.9146352959304906), ('epoqu', 0.37677800640918374), ('perrier', 0.37677540253032155), ('jouet', 0.37677326945610845), ('fuller', 0.26544421441232796), ('anarchist', 0.26544310299881108), ('forgetmenot', 0.2654381493861544), ('90046', 0.2654335766879275), ('speyburn', 0.25820676053362124), ('isc', 0.25820538933253084)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
