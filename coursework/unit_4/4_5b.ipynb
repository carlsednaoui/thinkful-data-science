{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cart-abandon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4666, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "\n",
    "# Remove null\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove \"?\"\n",
    "df = df[df.cart_abandon != \"?\"]\n",
    "\n",
    "# Make sure we're using ints\n",
    "df.cart_abandon = df.cart_abandon.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"all_text\"] = df[\"subject\"] + \" \" + df[\"full_text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_id</th>\n",
       "      <th>add_id</th>\n",
       "      <th>email_guid</th>\n",
       "      <th>sent_at</th>\n",
       "      <th>subject</th>\n",
       "      <th>full_text</th>\n",
       "      <th>r</th>\n",
       "      <th>email_url</th>\n",
       "      <th>cart_abandon</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>f3870de1-3ab6-3fed-3fe2-778a74f3197e</td>\n",
       "      <td>1/7/16 15:07</td>\n",
       "      <td>Welcome to Sephora Beauty Insider</td>\n",
       "      <td>Lorem, you're a Beauty Insider. Web Version SE...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.mailcharts.com/emails/f3870de1-3ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to Sephora Beauty Insider Lorem, you'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70</td>\n",
       "      <td>1/8/16 17:28</td>\n",
       "      <td>New year, new rewards</td>\n",
       "      <td>Lorem, the January rewards are here.** Web Ver...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.mailcharts.com/emails/0880fd5c-fbc...</td>\n",
       "      <td>0</td>\n",
       "      <td>New year, new rewards Lorem, the January rewar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_id  add_id                            email_guid       sent_at  \\\n",
       "0    2582    3742  f3870de1-3ab6-3fed-3fe2-778a74f3197e  1/7/16 15:07   \n",
       "1    2582    3742  0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70  1/8/16 17:28   \n",
       "\n",
       "                             subject  \\\n",
       "0  Welcome to Sephora Beauty Insider   \n",
       "1              New year, new rewards   \n",
       "\n",
       "                                           full_text  r  \\\n",
       "0  Lorem, you're a Beauty Insider. Web Version SE...  1   \n",
       "1  Lorem, the January rewards are here.** Web Ver...  2   \n",
       "\n",
       "                                           email_url  cart_abandon  \\\n",
       "0  https://www.mailcharts.com/emails/f3870de1-3ab...             0   \n",
       "1  https://www.mailcharts.com/emails/0880fd5c-fbc...             0   \n",
       "\n",
       "                                            all_text  \n",
       "0  Welcome to Sephora Beauty Insider Lorem, you'r...  \n",
       "1  New year, new rewards Lorem, the January rewar...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "import string\n",
    "\n",
    "\n",
    "# Steps: Clean up text, stemming, remove stop words and weird chars, tokenizer words\n",
    "\n",
    "# punctuation = list(set(string.punctuation))\n",
    "re_punctuation = \"\\#|\\.|\\>|\\/|\\)|\\\"|\\(|\\}|\\'|\\_|\\-|\\$|\\:|\\[|\\^|\\+|\\?|\\`|\\~|\\!|\\<|\\@|\\;|\\=|\\*|\\\\\\|\\{|\\&|\\]|\\||\\,|\\|\"\n",
    "stopwords_set = list(set(stopwords.words('english')))\n",
    "\n",
    "def get_unigram_sentence(sentence):\n",
    "    sentence_no_punc = re.sub(re_punctuation, \" \", sentence)\n",
    "    unigram = [word for word in word_tokenize(sentence_no_punc.lower()) if word not in stopwords_set]\n",
    "    return unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"tokenized_text\"] = df.all_text.apply(lambda x: get_unigram_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_id</th>\n",
       "      <th>add_id</th>\n",
       "      <th>email_guid</th>\n",
       "      <th>sent_at</th>\n",
       "      <th>subject</th>\n",
       "      <th>full_text</th>\n",
       "      <th>r</th>\n",
       "      <th>email_url</th>\n",
       "      <th>cart_abandon</th>\n",
       "      <th>all_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>f3870de1-3ab6-3fed-3fe2-778a74f3197e</td>\n",
       "      <td>1/7/16 15:07</td>\n",
       "      <td>Welcome to Sephora Beauty Insider</td>\n",
       "      <td>Lorem, you're a Beauty Insider. Web Version SE...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.mailcharts.com/emails/f3870de1-3ab...</td>\n",
       "      <td>0</td>\n",
       "      <td>Welcome to Sephora Beauty Insider Lorem, you'r...</td>\n",
       "      <td>[welcome, sephora, beauty, insider, lorem, bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582</td>\n",
       "      <td>3742</td>\n",
       "      <td>0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70</td>\n",
       "      <td>1/8/16 17:28</td>\n",
       "      <td>New year, new rewards</td>\n",
       "      <td>Lorem, the January rewards are here.** Web Ver...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.mailcharts.com/emails/0880fd5c-fbc...</td>\n",
       "      <td>0</td>\n",
       "      <td>New year, new rewards Lorem, the January rewar...</td>\n",
       "      <td>[new, year, new, rewards, lorem, january, rewa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_id  add_id                            email_guid       sent_at  \\\n",
       "0    2582    3742  f3870de1-3ab6-3fed-3fe2-778a74f3197e  1/7/16 15:07   \n",
       "1    2582    3742  0880fd5c-fbc5-eeb2-5bd3-8e352eae2b70  1/8/16 17:28   \n",
       "\n",
       "                             subject  \\\n",
       "0  Welcome to Sephora Beauty Insider   \n",
       "1              New year, new rewards   \n",
       "\n",
       "                                           full_text  r  \\\n",
       "0  Lorem, you're a Beauty Insider. Web Version SE...  1   \n",
       "1  Lorem, the January rewards are here.** Web Ver...  2   \n",
       "\n",
       "                                           email_url  cart_abandon  \\\n",
       "0  https://www.mailcharts.com/emails/f3870de1-3ab...             0   \n",
       "1  https://www.mailcharts.com/emails/0880fd5c-fbc...             0   \n",
       "\n",
       "                                            all_text  \\\n",
       "0  Welcome to Sephora Beauty Insider Lorem, you'r...   \n",
       "1  New year, new rewards Lorem, the January rewar...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [welcome, sephora, beauty, insider, lorem, bea...  \n",
       "1  [new, year, new, rewards, lorem, january, rewa...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from nltk.stem import SnowballStemmer\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# snow = SnowballStemmer(language='english')\n",
    "# stem = PorterStemmer()\n",
    "# word = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_stems(words):\n",
    "    return [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"stemmed_tokens\"] = df.tokenized_text.apply(lambda x: get_stems(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"stemmed_text\"] = df[\"stemmed_tokens\"].apply(lambda x: \" \".join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf = tfidf.fit(df[\"stemmed_text\"])\n",
    "X = tfidf.transform(df[\"stemmed_text\"])\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carl/anaconda/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_jobs=1, n_topics=2, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "# We know we have 2 labels\n",
    "lda = LDA(2)\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "    for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "        print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('œâ', 42.261067068335578), ('de', 10.786949926770131), ('harrod', 3.7519011027823455), ('para', 3.5388111515864202), ('rma', 3.355619376483622), ('oliv', 3.0269897005417681), ('armament', 2.955870948807878), ('en', 2.7033534878571714), ('dafiti', 2.6090830625857544), ('tu', 2.6082079620309471)]\n",
      "====================================================================================================\n",
      "Topic 1:\n",
      "[('email', 166.06755807926538), ('shop', 143.24441656288906), ('xxx', 138.93847089519465), ('com', 121.26218820122382), ('us', 117.63011084868855), ('order', 116.89001504493865), ('ship', 111.89316026181879), ('offer', 108.86971960435508), ('free', 105.40256830085487), ('pleas', 97.029312996402084)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nmf = NMF()\n",
    "# nmf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print_topics(nmf, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "y = df.cart_abandon\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93232131562302345"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1316,  106],\n",
       "       [   1,  158]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(lr.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_x = tfidf.transform([df.stemmed_text[2]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(example_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92929292929292928"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[332,  27],\n",
       "       [  1,  36]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(rf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(example_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
